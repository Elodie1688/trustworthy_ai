{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f80fc535",
   "metadata": {},
   "source": [
    "# Week 04 â€“ Other XAI approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbaa642",
   "metadata": {},
   "source": [
    "## set up\n",
    "\n",
    "Before running this notebook you'll need to run the following commands in your terminal:\n",
    "\n",
    "\n",
    "```\n",
    "# navigate to your folder with the course material (and the virtual environment) \n",
    "cd .../.../.../trustworthy_ai\n",
    "\n",
    "# clone repo for generating counterfactuals\n",
    "git clone https://github.com/tabearoeber/CE-OCL.git\n",
    "\n",
    "# create environment\n",
    "python3.9 -m venv tutorial4\n",
    "\n",
    "# activate the virtual environment Mac\n",
    "source tutorial4/bin/activate\n",
    "\n",
    "# install a packages\n",
    "pip install gurobipy numpy==1.24 scikit-learn==1.1.2 pandas==1.3.4 matplotlib ipykernel opticl Pyomo==6.2 gplearn\n",
    "\n",
    "# create kernel \n",
    "python -m ipykernel install --user --name=tutorial4\n",
    "\n",
    "# close the virtual environment\n",
    "deactivate\n",
    "```\n",
    "\n",
    "For Windows users, to activate the environment simply copy/paste the file path to the file `.\\ ...(name of virtual environment) \\Scripts\\activate` and hit enter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d3a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.dirname(os.getcwd())+'/CE-OCL/src')\n",
    "import embed_mip as em\n",
    "import ce_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3c5d75",
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "\n",
    "We are using the [Statlog (German Credit Data)](http://archive.ics.uci.edu) dataset. The German Credit dataset classifies people described by a set of 20 features as good or bad credit risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330546e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/credit/credit-g_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8f1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'target':'class',\n",
    "    'numerical':list(data.select_dtypes(\"int64\").columns),\n",
    "    'categorical':list(data.drop('class', axis=1).select_dtypes(\"object\").columns)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98888973",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Counterfactual Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode class to 0 and 1\n",
    "recode = {\"class\": {\"bad\": 0, \"good\": 1}}\n",
    "data = data.replace(recode)\n",
    "\n",
    "# X and y\n",
    "X = data.drop(d['target'], axis=1)\n",
    "y = data[d['target']]\n",
    "\n",
    "# pre-process data\n",
    "X, X_train, X_test, y_train, y_test, F_b, data_pip = ce_helpers.prep_data(X, y, d['numerical'],\n",
    "                                                             one_hot_encoding = True, scaling = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4115d0a6",
   "metadata": {},
   "source": [
    "## 1. Train a predictive model\n",
    "\n",
    "We use the code from the repo to train a predictive model. We do this because we'll need the model parameters later on to embed the model in the optimization formulation. When training with the functions written in this repo, the model information is automatically saved for later.\n",
    "\n",
    "We will try five different models: multilayer perception (mlp), logistic regression (linear), support vector machine (svm), random forest (rf), and a decision tree (cart). \n",
    "\n",
    "Then, we will look at the performance of each model and choose one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab6eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_list = ['mlp', 'linear', 'svm', 'rf', 'cart']\n",
    "\n",
    "outcome_dict = {'counterfactual_credit':{'task': 'binary', 'X features': X_train.columns, \n",
    "                                        'class': d['target'], 'alg_list': alg_list,\n",
    "                                        'X_train':X_train, 'X_test':X_test,\n",
    "                                        'y_train':y_train, \n",
    "                                          'y_test':y_test}}\n",
    "\n",
    "## uncomment if models should be trained\n",
    "ce_helpers.train_models(outcome_dict)\n",
    "\n",
    "performance = ce_helpers.perf_trained_models(outcome_dict)\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f4f57c",
   "metadata": {},
   "source": [
    "Here we can see the performance of each model on the test set. Let's use the svm for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d0c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "algorithms = {'counterfactual_credit':'svm'} # specificy model you chose\n",
    "              \n",
    "y_pred, y_pred_0, X_test_0, models = ce_helpers.load_model(algorithms, outcome_dict, 'counterfactual_credit') \n",
    "clf = models['counterfactual_credit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dff0e2",
   "metadata": {},
   "source": [
    "## 2. Preparation for optimization\n",
    "\n",
    "### load the model file\n",
    "\n",
    "We have prepared this file before. This file contains information about the model we need to embed in the formulation, like which type of model it is, in which .csv file the model parameters are saved, and what the lower and upper bounds are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_master = pd.read_csv('../04_otherXAI/model_master_credit.csv')\n",
    "model_master['features'] = [[col for col in X_train.columns]]\n",
    "model_master['model_type'] = algorithms['counterfactual_credit']\n",
    "model_master['save_path'] = f'results/{algorithms[\"counterfactual_credit\"]}/v1_counterfactual_credit_model.csv'\n",
    "model_master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb51b15",
   "metadata": {},
   "source": [
    "### choose a factual instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "u = X_test_0.iloc[i,:]\n",
    "# print(u)\n",
    "print('predicted label: %d' % (clf.predict([u])))\n",
    "u_df = u.to_frame().T\n",
    "u_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f9692e",
   "metadata": {},
   "source": [
    "### Criteria that are said to make a good counterfactual\n",
    "\n",
    "When it comes to counterfactual explanations, there are a lot of criteria that we aim to respect to generate a point that is a plausible and feasible point in practice. The following table comes from [our paper](https://arxiv.org/pdf/2209.10997.pdf), so you can read more about it there and look up the other references if you like. Our approach is called `CE-OCL`, which stands for Counterfactual Explanation using Optimization with Constraint Learning.\n",
    "\n",
    "<div>\n",
    "<img src=\"../img/CEs.png\" width=\"900\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650023a0",
   "metadata": {},
   "source": [
    "### trust region\n",
    "\n",
    "<div>\n",
    "<img src=\"../img/trust_region.png\" width=\"350\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092818d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_idx_1 = np.where(y_train==1)[0] # get index of y_train instances with value 1\n",
    "X1 = X_train.iloc[y_idx_1,:].copy().reset_index(drop=True) # get corresponding X_train values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e375b4c0",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "#### Q1: Explain what these criteria mean. \n",
    "\n",
    "...\n",
    "\n",
    "#### Q2: Explain to which of the criteria the trust region belongs and how the trust region works, i.e. how does it attempts to address this criterion?\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de1bfcb",
   "metadata": {},
   "source": [
    "## 3. Optimize\n",
    "\n",
    "The function that runs the actual optimization model requires a lot of parameters: \n",
    "- `X_train` -- the training data (`pd.DataFrame`)\n",
    "- `X1` -- the subset of the data that has 1 as value for the target (`pd.DataFrame`)\n",
    "- `u` -- the factual instance (`pd.Series`)\n",
    "- `F_r` -- numerical features (`list`)\n",
    "- `F_b` -- binary features (`list`)\n",
    "- `F_int` -- integer features (`list`)\n",
    "- `F_coh` -- a `dictionary` mapping each categorical feature to its dummy variables. This dictionary is required to ensure that maximum _one_ of the dummies for a categorical variable have value 1. \n",
    "- `I` -- immutable features (`list`)\n",
    "- `L` -- features that can only increase in their value (`list`)\n",
    "- `Pers_I` -- conditionally mutable features (`list`). These are categorical features that are ordered, like education level, where it is possible to move to a different ('superior') categorical, however not move below the _current_ category.\n",
    "- `P` -- features that can only take on values greater than 0 (`list`)\n",
    "- `sp` -- sparsity parameter (`bool`)\n",
    "- `mu` -- scaling parameter (`int`)\n",
    "- `tr_region` -- use trust region yes or no? (`bool`)\n",
    "- `enlarge_tr` -- enlarge the trust region? (`bool`)\n",
    "- `num_counterfactuals` -- nr of counterfactuals to generate (`int`)\n",
    "- `model_master` -- dataframe with info about constraints and model (`pd.DataFrame`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b570a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_r = d['numerical']\n",
    "F_int = ['num_dependents', 'existing_credits', 'residence_since']\n",
    "\n",
    "# for coherence\n",
    "F_coh = {}\n",
    "for f in d['categorical']:\n",
    "    F_coh[f] = [i for i in list(X_train.columns.difference(d['numerical'] + [d['target']])) if i.startswith('%s_' % f)]\n",
    "    \n",
    "F_coh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd351cb",
   "metadata": {},
   "source": [
    "## Part A: validity, proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CEs, CEs_, final_model = ce_helpers.opt(X_train, X1, u, \n",
    "                                        F_r = d['numerical'], # numerical\n",
    "                                        F_b = X_train.columns.difference(d['numerical']), # binary\n",
    "                                        F_int = ['num_dependents', 'existing_credits', 'residence_since'], # integer features \n",
    "                                        F_coh = F_coh, \n",
    "                                        I = [], # immutable\n",
    "                                        L = [], # greater or equal to current age\n",
    "                                        Pers_I = [], # conditionally mutable\n",
    "                                        P = [], # greater or equal to 0\n",
    "                                        sp = False, mu = 0, # sparsity\n",
    "                                        tr_region = False, enlarge_tr = False, # trust region\n",
    "                                        num_counterfactuals = 1, \n",
    "                                        model_master = model_master, \n",
    "                                        scaler = data_pip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd0137",
   "metadata": {},
   "source": [
    "### Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b02cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = ce_helpers.visualise_changes(clf, d, F_coh=F_coh, method = 'CE-OCL', CEs=CEs, CEs_ = CEs_, only_changes=True)\n",
    "df_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599cb1d3",
   "metadata": {},
   "source": [
    "#### Q3: Explain the table.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db0e72",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "The authors of the paper [Explaining machine learning classifiers through diverse counterfactual explanations](https://dl.acm.org/doi/abs/10.1145/3351095.3372850) propose some quantitative metrics to evaluate counterfactual explanations along the dimensions validity, proximity (categorical and continuous), sparsity, and diversity (categorical and continuous). The results are averaged over the generated counterfactuals.\n",
    "\n",
    "- `validity` -- ranges from 0 to 1, with 1 being the best value\n",
    "- `cat_prox` -- ranges from 0 to 1, with 1 being the best value\n",
    "- `cont_prox` -- ranges from -inf to 0, with 0 being the best value\n",
    "- `sparsity` -- ranges from 0 to 1, with 1 being the best value\n",
    "- `cat_diver` -- ranges from 0 to 1, with 1 being the best value\n",
    "- `cont_diver` -- ranges from 0 to +inf, the higher the better\n",
    "- `cont_count_divers` -- sparsity-based diversity -- ranges from 0 to 1, with 1 being the best value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c6861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = ce_helpers.visualise_changes(clf, d, F_coh=F_coh, method='CE-OCL', CEs=CEs, CEs_=CEs_)\n",
    "CE_perf = ce_helpers.evaluation(df_orig, d).set_index(pd.Index(['Part A']))\n",
    "CE_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28589d",
   "metadata": {},
   "source": [
    "#### Q4: Explain why the value for cat_prox is 1. Also explain why there are some None values.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0882a48e",
   "metadata": {},
   "source": [
    "## Part B: validity, proximity, sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CEs, CEs_, final_model = ce_helpers.opt(X_train, X1, u, \n",
    "                                        F_r = d['numerical'], # numerical\n",
    "                                        F_b = X_train.columns.difference(d['numerical']), # binary\n",
    "                                        F_int = ['num_dependents', 'existing_credits', 'residence_since'], # integer features \n",
    "                                        F_coh = F_coh, \n",
    "                                        I = [], # immutable\n",
    "                                        L = [], # greater or equal to current age\n",
    "                                        Pers_I = [], # conditionally mutable\n",
    "                                        P = [], # greater or equal to 0\n",
    "                                        sp = True, mu = 10000, # sparsity\n",
    "                                        tr_region = False, enlarge_tr = False, # trust region\n",
    "                                        num_counterfactuals = 1, \n",
    "                                        model_master = model_master, \n",
    "                                        scaler = data_pip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc71608",
   "metadata": {},
   "source": [
    "### Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = ce_helpers.visualise_changes(clf, d, F_coh=F_coh, method = 'CE-OCL', CEs=CEs, CEs_ = CEs_, only_changes=True)\n",
    "df_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714c23f6",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1550b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = ce_helpers.visualise_changes(clf, d, F_coh=F_coh, method='CE-OCL', CEs=CEs, CEs_=CEs_)\n",
    "CE_perf = pd.concat([CE_perf, ce_helpers.evaluation(df_orig, d)]).set_index(pd.Index(['Part A', 'Part B']))\n",
    "CE_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e16b9ac",
   "metadata": {},
   "source": [
    "#### Q5: How did the results change? Explain in light of the 'criterion' that we added in this part.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f943487",
   "metadata": {},
   "source": [
    "## Part C: validity, proximity, sparsity, diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e722139",
   "metadata": {},
   "outputs": [],
   "source": [
    "CEs, CEs_, final_model = ce_helpers.opt(X_train, X1, u, \n",
    "                                        F_r = d['numerical'], # numerical\n",
    "                                        F_b = X_train.columns.difference(d['numerical']), # binary\n",
    "                                        F_int = ['num_dependents', 'existing_credits', 'residence_since'], # integer features \n",
    "                                        F_coh = F_coh, \n",
    "                                        I = [], # immutable\n",
    "                                        L = [], # greater or equal to current age\n",
    "                                        Pers_I = [], # conditionally mutable\n",
    "                                        P = [], # greater or equal to 0\n",
    "                                        sp = True, mu = 10000, # sparsity\n",
    "                                        tr_region = False, enlarge_tr = False, # trust region\n",
    "                                        num_counterfactuals = 3, \n",
    "                                        model_master = model_master, \n",
    "                                        scaler = data_pip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e45df",
   "metadata": {},
   "source": [
    "### Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c333418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = ce_helpers.visualise_changes(clf, d, F_coh=F_coh, method = 'CE-OCL', CEs=CEs, CEs_ = CEs_, only_changes=True)\n",
    "df_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8a88cc",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b114c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = ce_helpers.visualise_changes(clf, d, F_coh=F_coh, method='CE-OCL', CEs=CEs, CEs_=CEs_)\n",
    "CE_perf = pd.concat([CE_perf, ce_helpers.evaluation(df_orig, d)]).set_index(pd.Index(['Part A', 'Part B', 'Part C']))\n",
    "CE_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9ba0d0",
   "metadata": {},
   "source": [
    "## Part D: validity, proximity, sparsity, diversity, actionability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa4a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that can only increase (become larger)\n",
    "L = ['age', 'residence_since']\n",
    "# L = ['residence_since']\n",
    "\n",
    "# immutable features\n",
    "I = ['personal_status_male div/sep', 'personal_status_male mar/wid','personal_status_male single',\n",
    "     'purpose_domestic appliance', 'purpose_education', 'purpose_furniture/equipment', 'purpose_new car',\n",
    "     'purpose_other', 'purpose_radio/tv', 'purpose_repairs', 'purpose_retraining', 'purpose_used car',\n",
    "     'foreign_worker_yes']\n",
    "\n",
    "employment = ['employment_unemployed', 'employment_<1', 'employment_1<=X<4','employment_4<=X<7', 'employment_>=7']\n",
    "Pers_I = [employment] # variables that must be considered for person specific immutable features\n",
    "\n",
    "P = ['duration', 'installment_commitment', 'num_dependents', 'credit_amount', 'existing_credits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CEs, CEs_, final_model = ce_helpers.opt(X_train, X1, u, \n",
    "                                        F_r = d['numerical'], # numerical\n",
    "                                        F_b = X_train.columns.difference(d['numerical']), # binary\n",
    "                                        F_int = ['num_dependents', 'existing_credits', 'residence_since'], # integer features \n",
    "                                        F_coh = F_coh, \n",
    "                                        I = I, # immutable\n",
    "                                        L = L, # greater or equal to current age\n",
    "                                        Pers_I = Pers_I, # conditionally mutable\n",
    "                                        P = P, # greater or equal to 0\n",
    "                                        sp = True, mu = 10000, # sparsity\n",
    "                                        tr_region = False, enlarge_tr = False, # trust region\n",
    "                                        num_counterfactuals = 3, \n",
    "                                        model_master = model_master, \n",
    "                                        scaler = data_pip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4350e5a9",
   "metadata": {},
   "source": [
    "### Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a04d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = ce_helpers.visualise_changes(clf, d, F_coh=F_coh, method = 'CE-OCL', CEs=CEs, CEs_ = CEs_, only_changes=True)\n",
    "df_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca6bd8",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bf55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = ce_helpers.visualise_changes(clf, d, F_coh=F_coh, method='CE-OCL', CEs=CEs, CEs_=CEs_)\n",
    "CE_perf = pd.concat([CE_perf, ce_helpers.evaluation(df_orig, d)]).set_index(pd.Index(['Part A', 'Part B', 'Part C', 'Part D']))\n",
    "CE_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876c6df3",
   "metadata": {},
   "source": [
    "#### Q6: What is `Pers_I`?\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c00d9",
   "metadata": {},
   "source": [
    "## Part E: validity, proximity, sparsity, diversity, actionability, trust region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: CEs, CEs_, final_model = ce_helpers.opt(X_train, X1, u, \n",
    "                                        F_r = d['numerical'], # numerical\n",
    "                                        F_b = X_train.columns.difference(d['numerical']), # binary\n",
    "                                        F_int = ['num_dependents', 'existing_credits', 'residence_since'], # integer features \n",
    "                                        F_coh = F_coh, \n",
    "                                        I = I, # immutable\n",
    "                                        L = L, # greater or equal to current age\n",
    "                                        Pers_I = Pers_I, # conditionally mutable\n",
    "                                        P = P, # greater or equal to 0\n",
    "                                        sp = True, mu = 10000, # sparsity\n",
    "                                        tr_region = True, enlarge_tr = False, # trust region\n",
    "                                        num_counterfactuals = 3, \n",
    "                                        model_master = model_master, \n",
    "                                        scaler = data_pip)\n",
    "except:\n",
    "    print('----TRUST REGION IS BEING ENLARGED----')\n",
    "    CEs, CEs_, final_model = ce_helpers.opt(X_train, X1, u, \n",
    "                                        F_r = d['numerical'], # numerical\n",
    "                                        F_b = X_train.columns.difference(d['numerical']), # binary\n",
    "                                        F_int = ['num_dependents', 'existing_credits', 'residence_since'], # integer features \n",
    "                                        F_coh = F_coh, \n",
    "                                        I = I, # immutable\n",
    "                                        L = L, # greater or equal to current age\n",
    "                                        Pers_I = Pers_I, # conditionally mutable\n",
    "                                        P = P, # greater or equal to 0\n",
    "                                        sp = True, mu = 10000, # sparsity\n",
    "                                        tr_region = True, enlarge_tr = True, # trust region\n",
    "                                        num_counterfactuals = 3, \n",
    "                                        model_master = model_master, \n",
    "                                        scaler = data_pip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05931cce",
   "metadata": {},
   "source": [
    "### Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea162fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e = ce_helpers.visualise_changes(clf, d, F_coh=F_coh, method = 'CE-OCL', CEs=CEs, CEs_ = CEs_, only_changes=True)\n",
    "df_e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8753d1",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = ce_helpers.visualise_changes(clf, d, F_coh=F_coh, method='CE-OCL', CEs=CEs, CEs_=CEs_)\n",
    "CE_perf = pd.concat([CE_perf, ce_helpers.evaluation(df_orig, d)]).set_index(pd.Index(['Part A', 'Part B', 'Part C', 'Part D', 'Part E']))\n",
    "CE_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c2c78",
   "metadata": {},
   "source": [
    "## 4. Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d71a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pd.concat([df_a, df_b, df_c, df_d, df_e])\n",
    "df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CE_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ed64b",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Symbolic regression\n",
    "\n",
    "\n",
    "In this notebook you will use different approaches to symbolic regression. It consists of the following sections:\n",
    "\n",
    "1. GPLearn for symbolic regression, and other non-symbolic regression methods (DT and RF)\n",
    "2. srLP for symbolic regression, and compare to GPLearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL FIRST. Do not change.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.utils.random import check_random_state\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4921c",
   "metadata": {},
   "source": [
    "## 1. Non-Symbolic Regression Methods\n",
    "\n",
    "First, we create the data used for the methods mentioned above. The code below creates a surfaceplot of all points $(x1,x2)$ between -1 and 1 for two features $x1$ and $x2$, according to the equation $y_{truth} = x1^2 - x1^2 + x2 - 1$. In the methods below we will try to find an equation that best fits $y_{truth}$. \n",
    "\n",
    "1. GPLearn for Symbolic Regression\n",
    "2. Decision Tree Regression\n",
    "3. Random Forest Regression\n",
    "\n",
    "Recall that in case of symbolic regression, the goal is to find an equation. To compare to other non-linear methods, we include Decision Tree (DT) Regression and Random Forest (RF) Regression. However, these methods will not produce an equation, but will simply train a DT or RF that best matches the given data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22ddc9b",
   "metadata": {},
   "source": [
    "### create surface plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46170f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL. Do not change.\n",
    "\n",
    "# Creating surface plot of y_truth\n",
    "x1 = np.arange(-1, 1, 1/10.)\n",
    "x2 = np.arange(-1, 1, 1/10.)\n",
    "x1, x2 = np.meshgrid(x1, x2)\n",
    "y_truth = x1**2 - x2**2 + x2 - 1\n",
    "\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "surf = ax.plot_surface(x1, x2, y_truth, rstride=1, cstride=1,\n",
    "                       color='green', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9dd2b",
   "metadata": {},
   "source": [
    "#### Q1. Suppose a new sample $(x1,x2)$ in $[-1,1]$ comes in. Where whould the predicted output lie in this plot?\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac69ffb0",
   "metadata": {},
   "source": [
    "### Generate synthetic data\n",
    "\n",
    "We'll now create the actual train and test data to use on GPLearn, DT Regression and RF Regression. The train dataset will consist of a 100 samples. We use $$y = x_1^2 - x_2^2 + x_2 - 1$$. \n",
    "\n",
    "Running the cell below shows you the first five samples of all 50 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c670150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL. Do not change.\n",
    "\n",
    "rng = check_random_state(0)\n",
    "\n",
    "# Training samples\n",
    "X_train = rng.uniform(-1, 1, 100).reshape(50, 2)\n",
    "y_train = X_train[:, 0]**2 - X_train[:, 1]**2 + X_train[:, 1] - 1\n",
    "\n",
    "train_df = pd.DataFrame({'x1': X_train[:, 0], 'x2': X_train[:, 1], 'y': y_train})\n",
    "print(train_df.head())\n",
    "\n",
    "# Testing samples\n",
    "X_test = rng.uniform(-1, 1, 100).reshape(50, 2)\n",
    "y_test = X_test[:, 0]**2 - X_test[:, 1]**2 + X_test[:, 1] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde79dcb",
   "metadata": {},
   "source": [
    "## 1.1 GPLearn\n",
    "\n",
    "We first start with training a GPLearn model. Recall that this model performs symbolic regression based on genetic programming. Thus the resulting output is an equation that best fits the dataset above, after performing tree operations based on Darwinian evolution (cross-over, mutation, selection, replication). The output will be given by a set of arithmetic operators: addition, substraction, division and multiplication. \n",
    "\n",
    "Examples are `add(x1,3.0)` means $x_1+3$, or `sub(x2,add(x1,3.0))` means $x_2-(x_1+3)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f1b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL. Do not change.\n",
    "\n",
    "# Fit SymbolicRegressor\n",
    "est_gp = SymbolicRegressor(population_size=5000,\n",
    "                           generations=20, stopping_criteria=0.01,\n",
    "                           p_crossover=0.7, p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.05, p_point_mutation=0.1,\n",
    "                           max_samples=0.9, verbose=1,\n",
    "                           parsimony_coefficient=0.01, random_state=0)\n",
    "est_gp.fit(X_train, y_train)\n",
    "\n",
    "# Generate equation\n",
    "print(est_gp._program)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5035ee",
   "metadata": {},
   "source": [
    "#### Q2. Give the resulting equation and show that GPLearn found the original equation exactly.\n",
    "Tip: `X0` = x1 and `X1` = x2\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298f68a0",
   "metadata": {},
   "source": [
    "## 1.2 Other regression methods\n",
    "\n",
    "We train a Decision Tree Regression model and Random Forest Regression model. Tree Regression methods aim to find a tree that will travel through the branches to end up in a note with the value closest to the target value. For example, given sample a new samle $(x1,x2) = (4.0, 2.0)$. The tree regressor may create decision rules such as `(x1 <= 5.0) and (x2 <= 3.0), then y = 3.5`. The decision rules created should produce output values that closely matches the y-column of our datadet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2206c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL. Do not change.\n",
    "\n",
    "# Fit Decision Tree and Random Forest regression\n",
    "est_tree = DecisionTreeRegressor()\n",
    "est_tree.fit(X_train, y_train)\n",
    "est_rf = RandomForestRegressor()\n",
    "est_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f697ea9",
   "metadata": {},
   "source": [
    "We visualize the data below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b481c86",
   "metadata": {},
   "source": [
    "## 1.3 Inspecting all three methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL. Do not change.\n",
    "\n",
    "y_gp = est_gp.predict(np.c_[x1.ravel(), x2.ravel()]).reshape(x1.shape)\n",
    "score_gp = est_gp.score(X_test, y_test)\n",
    "y_tree = est_tree.predict(np.c_[x1.ravel(), x2.ravel()]).reshape(x1.shape)\n",
    "score_tree = est_tree.score(X_test, y_test)\n",
    "y_rf = est_rf.predict(np.c_[x1.ravel(), x2.ravel()]).reshape(x1.shape)\n",
    "score_rf = est_rf.score(X_test, y_test)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i, (y, score, title) in enumerate([(y_truth, None, \"Ground Truth\"),\n",
    "                                       (y_gp, score_gp, \"SymbolicRegressor\"),\n",
    "                                       (y_tree, score_tree, \"DecisionTreeRegressor\"),\n",
    "                                       (y_rf, score_rf, \"RandomForestRegressor\")]):\n",
    "\n",
    "    ax = fig.add_subplot(2, 2, i+1, projection='3d')\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    surf = ax.plot_surface(x1, x2, y, rstride=1, cstride=1, color='green', alpha=0.5)\n",
    "    points = ax.scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "    if score is not None:\n",
    "        score = ax.text(-.7, 1, .2, \"$R^2 =\\/ %.6f$\" % score, 'x', fontsize=8)\n",
    "    plt.title(title, fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b3571a",
   "metadata": {},
   "source": [
    "#### Q3. Which method seems to work best according to the plot? Explain your answer. Is this also what you expected?\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
